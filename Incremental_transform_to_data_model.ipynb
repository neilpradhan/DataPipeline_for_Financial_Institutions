{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Incremental Data\n",
    "\n",
    "Assuming that we have already done the first load and our data is in the datawarehouse.\n",
    "For new incremental data or second and subsequent runs, we will run this file which makes sure that if there is a new field in the dimensions then we will add that and make appropriate addition to the surrogate keys as well, including changes to the data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to save DataFrame to CSV\n",
    "def save_to_csv(df, file_name):\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "def add_scd2_columns(df):\n",
    "    df['start_date'] = datetime.now()\n",
    "    df['end_date'] = pd.to_datetime('2262-04-11')\n",
    "    df['active_flag'] = 'Y'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Existing Dimensional tables\n",
    "existing_customers_df = pd.read_csv('Data_warehouse/unique_customers.csv')\n",
    "existing_countries_df = pd.read_csv('Data_warehouse/unique_countries.csv')\n",
    "existing_currencies_df = pd.read_csv('Data_warehouse/unique_currencies.csv')\n",
    "existing_account_names_df = pd.read_csv('Data_warehouse/unique_account_names.csv')\n",
    "existing_date_dimension_df = pd.read_csv('Data_warehouse/date_dimension.csv')\n",
    "existing_loan_type_df = pd.read_csv('Data_warehouse/loan_type.csv')\n",
    "existing_deposit_type_df = pd.read_csv('Data_warehouse/deposit_type.csv')\n",
    "\n",
    "\n",
    "# Existing Fact tables\n",
    "\n",
    "existing_fact_deposits_df = pd.read_csv('Data_warehouse/fact_deposits.csv')\n",
    "existing_fact_accounts_df = pd.read_csv('Data_warehouse/fact_accounts.csv')\n",
    "existing_fact_loans_df = pd.read_csv('Data_warehouse/fact_loans.csv')\n",
    "\n",
    "# New data\n",
    "\n",
    "new_accounts_df = pd.read_excel(\"Processed_file\\Cleaned_data\\cleaned_accounts.xlsx\", sheet_name='Sheet1')\n",
    "new_deposits_df = pd.read_excel(\"Processed_file\\Cleaned_data\\cleaned_deposits.xlsx\", sheet_name='Sheet1')\n",
    "new_loans_df = pd.read_excel(\"Processed_file\\Cleaned_data\\cleaned_loans.xlsx\", sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "new_accounts_df.rename(columns={'amount': 'account_amount'}, inplace=True)\n",
    "new_deposits_df.rename(columns={'amount': 'deposit_amount'}, inplace=True)\n",
    "new_loans_df.rename(columns={'amount': 'loan_amount'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update new Customer Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Identify unique customers from new deposits and loans\n",
    "unique_new_customers_deposits = new_deposits_df[['customer', 'customer_type']].drop_duplicates()\n",
    "unique_new_customers_loans = new_loans_df[['customer', 'customer_type']].drop_duplicates()\n",
    "\n",
    "# Combine the new unique customers and remove duplicates\n",
    "all_unique_new_customers = pd.concat([unique_new_customers_deposits, unique_new_customers_loans]).drop_duplicates()\n",
    "\n",
    "# Find new customers that are not already in the existing customers table\n",
    "new_customers = pd.merge(all_unique_new_customers, existing_customers_df[['customer', 'customer_type']],\n",
    "                         on=['customer', 'customer_type'], how='left', indicator=True)\n",
    "new_customers = new_customers[new_customers['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "# print(new_customers)\n",
    "# Assign new surrogate keys to the new customers and scd type 2 \n",
    "if not new_customers.empty:\n",
    "    max_existing_key = existing_customers_df['customer_key'].max()\n",
    "    new_customers['customer_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_customers))\n",
    "\n",
    "    new_customers = add_scd2_columns(new_customers)\n",
    "    \n",
    "    ## apending the data to the existing dimensional table in data warehouse if there is any new customer\n",
    "    new_customers.to_csv(\"Data_warehouse/unique_customers.csv\", mode='a', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update new Country Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Identify unique countries from new deposits and loans\n",
    "unique_countries_deposits = new_deposits_df['country'].unique()\n",
    "unique_countries_loans = new_loans_df['country'].unique()\n",
    "\n",
    "# Combine the unique countries and remove duplicates\n",
    "all_unique_countries = np.unique(np.concatenate((unique_countries_deposits, unique_countries_loans)))\n",
    "\n",
    "\n",
    "# Create a DataFrame for unique new countries\n",
    "unique_countries_df = pd.DataFrame(all_unique_countries, columns=['country'])\n",
    "\n",
    "\n",
    "# Find new countries that are not already in the existing countries table\n",
    "new_countries = pd.merge(unique_countries_df, existing_countries_df[['country']],\n",
    "                         on='country', how='left', indicator=True)\n",
    "new_countries = new_countries[new_countries['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "\n",
    "\n",
    "# Assign new surrogate keys to the new countries\n",
    "if not new_countries.empty:\n",
    "    max_existing_key = existing_countries_df['country_key'].max() if not existing_countries_df.empty else 0\n",
    "    new_countries['country_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_countries))\n",
    "\n",
    "    new_countries = add_scd2_columns(new_countries)\n",
    "\n",
    "    new_countries.to_csv(\"Data_warehouse/unique_countries.csv\", mode='a', header=False, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Update new Currency Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Identify unique currencies from new deposits and loans\n",
    "unique_currencies_deposits = new_deposits_df['currency'].unique()\n",
    "unique_currencies_loans = new_loans_df['currency'].unique()\n",
    "\n",
    "# Combine the unique currencies and remove duplicates\n",
    "all_unique_currencies = np.unique(np.concatenate((unique_currencies_deposits, unique_currencies_loans)))\n",
    "\n",
    "# Create a DataFrame for unique new currencies\n",
    "unique_currencies_df = pd.DataFrame(all_unique_currencies, columns=['currency'])\n",
    "\n",
    "# Find new currencies that are not already in the existing currencies table\n",
    "new_currencies = pd.merge(unique_currencies_df, existing_currencies_df[['currency']],\n",
    "                          on='currency', how='left', indicator=True)\n",
    "new_currencies = new_currencies[new_currencies['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "# Assign new surrogate keys to the new currencies\n",
    "if not new_currencies.empty:\n",
    "    max_existing_key = existing_currencies_df['currency_key'].max() if not existing_currencies_df.empty else 0\n",
    "    new_currencies['currency_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_currencies))\n",
    "\n",
    "    new_currencies = add_scd2_columns(new_currencies)\n",
    "    # Append new currencies to the existing currencies DataFrame\n",
    "    new_currencies.to_csv(\"Data_warehouse/unique_currencies.csv\", mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update new Accounts_Name_Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Identify unique account names from new accounts\n",
    "unique_account_names = pd.DataFrame(new_accounts_df['account_name'].unique(), columns=['account_name'])\n",
    "\n",
    "# Find new account names that are not already in the existing account names table\n",
    "new_account_names = pd.merge(unique_account_names, existing_account_names_df[['account_name']],\n",
    "                             on='account_name', how='left', indicator=True)\n",
    "new_account_names = new_account_names[new_account_names['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "# Assign new surrogate keys to the new account names\n",
    "if not new_account_names.empty:\n",
    "    max_existing_key = existing_account_names_df['account_name_key'].max() if not existing_account_names_df.empty else 0\n",
    "    new_account_names['account_name_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_account_names))\n",
    "\n",
    "\n",
    "    new_account_names = add_scd2_columns(new_account_names)\n",
    "    # Append new account names to the existing account names DataFrame\n",
    "\n",
    "    new_account_names.to_csv(\"Data_warehouse/unique_account_names.csv\", mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update new Loan Type Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Identify unique loan types from new loans\n",
    "unique_new_loan_types = new_loans_df['loan_type'].unique()\n",
    "\n",
    "# Create a DataFrame for unique new loan types\n",
    "new_loan_types_df = pd.DataFrame(unique_new_loan_types, columns=['loan_type'])\n",
    "\n",
    "# Find new loan types that are not already in the existing loan types table\n",
    "new_loan_types = pd.merge(new_loan_types_df, existing_loan_type_df[['loan_type']],\n",
    "                          on='loan_type', how='left', indicator=True)\n",
    "new_loan_types = new_loan_types[new_loan_types['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "# Assign new surrogate keys to the new loan types\n",
    "if not new_loan_types.empty:\n",
    "    max_existing_key = existing_loan_type_df['loan_type_key'].max() if not existing_loan_type_df.empty else 0\n",
    "    new_loan_types['loan_type_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_loan_types))\n",
    "\n",
    "    new_loan_types = add_scd2_columns(new_loan_types)\n",
    "    # Append new loan types to the existing loan types DataFrame\n",
    "    new_loan_types.to_csv(\"Data_warehouse/loan_type.csv\", mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update new Deposit Type Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Identify unique deposit types from new deposits\n",
    "unique_new_deposit_types = new_deposits_df['deposit_type'].unique()\n",
    "\n",
    "# Create a DataFrame for unique new deposit types\n",
    "new_deposit_types_df = pd.DataFrame(unique_new_deposit_types, columns=['deposit_type'])\n",
    "\n",
    "# Find new deposit types that are not already in the existing deposit types table\n",
    "new_deposit_types = pd.merge(new_deposit_types_df, existing_deposit_type_df[['deposit_type']],\n",
    "                             on='deposit_type', how='left', indicator=True)\n",
    "new_deposit_types = new_deposit_types[new_deposit_types['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "# Assign new surrogate keys to the new deposit types\n",
    "if not new_deposit_types.empty:\n",
    "    max_existing_key = existing_deposit_type_df['deposit_type_key'].max() if not existing_deposit_type_df.empty else 0\n",
    "    new_deposit_types['deposit_type_key'] = range(max_existing_key + 1, max_existing_key + 1 + len(new_deposit_types))\n",
    "\n",
    "    new_deposit_types = add_scd2_columns(new_deposit_types)\n",
    "    # Append new deposit types to the existing deposit types in data warehouse\n",
    "    new_deposit_types.to_csv(\"Data_warehouse/deposit_type.csv\", mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maping Dimensions to Facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_accounts_df = new_accounts_df.copy()\n",
    "new_fact_deposits_df = new_deposits_df.copy()\n",
    "new_fact_loans_df = new_loans_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maping date_dimension to Fact_tables\n",
    "1. Map all the dates with the key \n",
    "2. Drop the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map dates to date keys\n",
    "def map_date_to_key(df, date_column):\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df[date_column + '_key'] = df[date_column].dt.strftime('%Y%m%d').astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Add date keys to fact_accounts\n",
    "fact_accounts = map_date_to_key(new_fact_accounts_df, 'reference_date')\n",
    "\n",
    "# Add date keys to fact_deposits\n",
    "fact_deposits = map_date_to_key(new_fact_deposits_df, 'start_date')\n",
    "fact_deposits = map_date_to_key(new_fact_deposits_df, 'maturity_date')\n",
    "fact_deposits = map_date_to_key(new_fact_deposits_df, 'reference_date')\n",
    "\n",
    "# Add date keys to fact_loans\n",
    "fact_loans = map_date_to_key(new_fact_loans_df, 'start_date')\n",
    "fact_loans = map_date_to_key(new_fact_loans_df, 'maturity_date')\n",
    "fact_loans = map_date_to_key(new_fact_loans_df, 'reference_date')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_deposits_df.drop(columns = ['start_date','maturity_date','reference_date'], inplace=True)\n",
    "new_fact_loans_df.drop(columns = ['start_date','maturity_date','reference_date'], inplace=True)\n",
    "new_fact_accounts_df.drop(columns=['reference_date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We have all the updated dimension tables in the data warehouse which now includes additional dimensions if included in the incremental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_customers_df = pd.read_csv('Data_warehouse/unique_customers.csv')\n",
    "updated_countries_df = pd.read_csv('Data_warehouse/unique_countries.csv')\n",
    "updated_currencies_df = pd.read_csv('Data_warehouse/unique_currencies.csv')\n",
    "updated_account_names_df = pd.read_csv('Data_warehouse/unique_account_names.csv')\n",
    "updated_date_dimension_df = pd.read_csv('Data_warehouse/date_dimension.csv')\n",
    "updated_loan_type_df = pd.read_csv('Data_warehouse/loan_type.csv')\n",
    "updated_deposit_type_df = pd.read_csv('Data_warehouse/deposit_type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maping updated_cutomer_dimension to fact_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_customer_to_key(df, unique_customers_df):\n",
    "    df = df.merge(updated_customers_df[['customer', 'customer_key']], on='customer', how='left')\n",
    "    # df.drop(columns=['customer'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Add customer_key to fact_deposits and drop the original customer column\n",
    "new_fact_deposits_df = map_customer_to_key(fact_deposits,updated_customers_df )\n",
    "\n",
    "# Add customer_key to fact_loans and drop the original customer column\n",
    "new_fact_loans_df = map_customer_to_key(fact_loans,updated_customers_df )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_deposits_df.drop(columns=['customer','customer_type'], inplace=True)\n",
    "new_fact_loans_df.drop(columns=['customer','customer_type'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maping updated_account_name dimensions to fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_account_name_to_key(df, account_name_df):\n",
    "    df = df.merge(updated_account_names_df, on='account_name', how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "new_fact_accounts_df = map_account_name_to_key(new_fact_accounts_df, updated_account_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_accounts_df.drop(columns=['account_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maping Updated_Currency dimension to  fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_currency_to_key(df, unique_currencies_df):\n",
    "    df = df.merge(updated_currencies_df, on='currency', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Add currency_key to fact_deposits and drop the original currency column\n",
    "new_fact_deposits_df = map_currency_to_key(new_fact_deposits_df, updated_currencies_df)\n",
    "\n",
    "# Add currency_key to fact_loans and drop the original currency column\n",
    "new_fact_loans_df = map_currency_to_key(new_fact_loans_df, updated_currencies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_deposits_df.drop(columns=['currency'], inplace= True)\n",
    "new_fact_loans_df.drop(columns=['currency'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Updated Country dimension to Fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_country_to_key(df, unique_countries_df):\n",
    "    df = df.merge(updated_countries_df, on='country', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Add country_key to fact_deposits and drop the original country column\n",
    "new_fact_deposits_df = map_country_to_key(new_fact_deposits_df, updated_countries_df)\n",
    "\n",
    "# Add country_key to fact_loans and drop the original country column\n",
    "new_fact_loans_df = map_country_to_key(new_fact_loans_df, updated_countries_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_deposits_df.drop(columns=['country'], inplace= True)\n",
    "new_fact_loans_df.drop(columns=['country'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Updated Deposit_type dimensions to  Fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_deposit_type_to_key(df, deposit_type_df):\n",
    "    df = df.merge(updated_deposit_type_df, on='deposit_type', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Add deposit_type_key to fact_deposits and drop the original deposit_type column\n",
    "new_fact_deposits_df = map_deposit_type_to_key(new_fact_deposits_df, updated_deposit_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_deposits_df.drop(columns=['deposit_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Updated Loan_type dimensions to Fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_loan_type_to_key(df, loan_type_df):\n",
    "    df = df.merge(updated_loan_type_df, on='loan_type', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Add loan_type_key to fact_loans and drop the original loan_type column\n",
    "new_fact_loans_df = map_loan_type_to_key(new_fact_loans_df, updated_loan_type_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fact_loans_df.drop(columns=['loan_type'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Final new incremental data for Loading in data warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Persisted maximum surrogate keys to maintain primary key in fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>max_deposits_surr_primarykey</th>\n",
       "      <th>max_account_surr_primarykey</th>\n",
       "      <th>max_surr_primarykey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fact_deposits</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact_accounts</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact_loans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      table_name  max_deposits_surr_primarykey  max_account_surr_primarykey  \\\n",
       "0  fact_deposits                            90                            0   \n",
       "1  fact_accounts                             0                           16   \n",
       "2     fact_loans                             0                            0   \n",
       "\n",
       "   max_surr_primarykey  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                  300  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_keys_df = pd.read_csv('Data_warehouse/max_surr_keys.csv')\n",
    "\n",
    "max_keys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final new Fact accounts data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_accounts_key = max_keys_df[max_keys_df['table_name'] == 'fact_accounts']['max_account_surr_primarykey'].iloc[0]\n",
    "\n",
    "# Increment the surrogate primary keys for the new records\n",
    "new_fact_accounts_df['account_surr_primarykey'] = range(int(max_accounts_key) + 1, int(max_accounts_key) + 1 + len(new_fact_accounts_df))\n",
    "\n",
    "new_fact_accounts_df = new_fact_accounts_df[['account_number', 'account_amount','account_surr_primarykey','account_type', 'ingest_date_time', 'reference_date_key', 'account_name_key']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final new Fact loans data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_loans_key = max_keys_df[max_keys_df['table_name'] == 'fact_loans']['max_surr_primarykey'].iloc[0]\n",
    "\n",
    "new_fact_loans_df['loans_surr_primarykey'] =  range(int(max_loans_key) + 1, int(max_loans_key) + 1 + len(new_fact_loans_df))\n",
    "new_fact_loans_df = new_fact_loans_df[['loan_amount','exchange_rate','ingest_date_time','loans_surr_primarykey','start_date_key','maturity_date_key','reference_date_key','customer_key','currency_key','country_key','loan_type_key']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final new Facts Deposits Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_deposits_key = max_keys_df[max_keys_df['table_name'] == 'fact_deposits']['max_deposits_surr_primarykey'].iloc[0]\n",
    "\n",
    "\n",
    "new_fact_deposits_df['deposits_surr_primarykey'] = range(int(max_deposits_key) + 1, int(max_deposits_key) + 1 + len(new_fact_deposits_df))\n",
    "new_fact_deposits_df = new_fact_deposits_df[['deposit_amount','exchange_rate','ingest_date_time','deposits_surr_primarykey','start_date_key','maturity_date_key','reference_date_key','customer_key','currency_key','country_key','deposit_type_key']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append fact tables to the data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append fact_deposits_df to fact_deposits.csv\n",
    "new_fact_deposits_df.to_csv('fact_deposits.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# Append fact_loans_df to fact_loans.csv\n",
    "new_fact_loans_df.to_csv('fact_loans.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# Append fact_accounts_df to fact_accounts.csv\n",
    "new_fact_accounts_df.to_csv('fact_accounts.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the max surrogate key and Persisting the same in the data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>max_deposits_surr_primarykey</th>\n",
       "      <th>max_account_surr_primarykey</th>\n",
       "      <th>max_surr_primarykey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fact_deposits</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact_accounts</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact_loans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      table_name  max_deposits_surr_primarykey  max_account_surr_primarykey  \\\n",
       "0  fact_deposits                           180                            0   \n",
       "1  fact_accounts                             0                           32   \n",
       "2     fact_loans                             0                            0   \n",
       "\n",
       "   max_surr_primarykey  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                  600  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create the Data_warehouse folder if it doesn't exist\n",
    "os.makedirs('Data_warehouse', exist_ok=True)\n",
    "\n",
    "\n",
    "max_deposits_key = new_fact_deposits_df['deposits_surr_primarykey'].max()\n",
    "max_accounts_key = new_fact_accounts_df['account_surr_primarykey'].max()\n",
    "max_loans_key = new_fact_loans_df['loans_surr_primarykey'].max()\n",
    "\n",
    "\n",
    "\n",
    "max_keys_data = [\n",
    "    {\"table_name\": \"fact_deposits\", \"max_deposits_surr_primarykey\": max_deposits_key},\n",
    "    {\"table_name\": \"fact_accounts\", \"max_account_surr_primarykey\": max_accounts_key},\n",
    "    {\"table_name\": \"fact_loans\", \"max_surr_primarykey\": max_loans_key}\n",
    "]\n",
    "max_keys_df = pd.DataFrame(max_keys_data)\n",
    "\n",
    "max_keys_df['max_deposits_surr_primarykey'] = max_keys_df['max_deposits_surr_primarykey'].fillna(0).astype(int)\n",
    "max_keys_df['max_account_surr_primarykey'] = max_keys_df['max_account_surr_primarykey'].fillna(0).astype(int)\n",
    "max_keys_df['max_surr_primarykey'] = max_keys_df['max_surr_primarykey'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Save the max keys data to a CSV file\n",
    "max_keys_df.to_csv('Data_warehouse/max_keys.csv', index=False)\n",
    "\n",
    "# print(\"Max keys data saved to Data_warehouse/max_surr_keys.csv\")\n",
    "max_keys_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending and Updating Data in the Data Warehouse\n",
    "\n",
    "This section describes the process for appending new data to the existing fact tables and replacing the dimension tables with updated versions in the data warehouse.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Append New Data to Fact Tables**:\n",
    "   - Append the new records: new_fact_accounts_df, new_fact_loans_df, new_fact_deposits_df  with the updated surrogate primary keys to the existing fact tables.\n",
    "\n",
    "\n",
    "2. **Changes with Dimensional Tables**\n",
    "-  For the Dimensional tables in the data warehouse, if there are any deprecated dimensions, we can change the active_flag from 'Y' to 'N' and update the end_date according to the business rules\n",
    " \n",
    "\n",
    "3. **Update the Max surrogate Primary key dataframe to the warehouse**\n",
    "- Make sure to update the max surrogate keys in the data warehouse, every time Fact tables are filled and save it to the data warehouse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advicense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

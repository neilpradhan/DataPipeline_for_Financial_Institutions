{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Data Quality and pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the schema\n",
    "dtype_schema = {\n",
    "    \"account_number\": \"object\",\n",
    "    \"amount\": \"float64\",\n",
    "    \"account_name\": \"object\",\n",
    "    \"account_type\": \"object\"\n",
    "}\n",
    "\n",
    "# Columns that should be parsed as dates\n",
    "date_columns = [\"reference_date\"]\n",
    "\n",
    "# Custom date parser for the specific date format in the Excel file\n",
    "date_parser = lambda x: pd.to_datetime(x, format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Read the Excel file with the specified schema and date format\n",
    "file_path = \"Datasets/Data Engineer Case Study - Data.xlsx\"\n",
    "accounts_df = pd.read_excel(file_path, sheet_name='Accounts', dtype=dtype_schema, parse_dates=date_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "accounts_df['ingest_date_time'] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   account_number    18 non-null     object        \n",
      " 1   amount            18 non-null     float64       \n",
      " 2   account_name      18 non-null     object        \n",
      " 3   account_type      18 non-null     object        \n",
      " 4   reference_date    18 non-null     datetime64[ns]\n",
      " 5   ingest_date_time  18 non-null     datetime64[us]\n",
      "dtypes: datetime64[ns](1), datetime64[us](1), float64(1), object(3)\n",
      "memory usage: 992.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "accounts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "original_output_path = 'Processed_file/Original_data'\n",
    "os.makedirs(original_output_path, exist_ok=True)\n",
    "original_output_file_path = os.path.join(original_output_path, 'original_accounts_with_ingest_date_time.xlsx')\n",
    "accounts_df.to_excel(original_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation Checks\n",
    "\n",
    "The following data validation checks have been performed on the dataframe:\n",
    "\n",
    "1. **Missing Values Check**\n",
    "   - **Description:** Checks if there are any missing values in the dataframe.\n",
    "   - **Action:** Collects rows with missing values and records an error comment: \"Missing values in the row\".\n",
    "\n",
    "2. **Duplicate Account Numbers on the Same Reference Date Check**\n",
    "   - **Description:** Checks for duplicate account numbers on the same reference date.\n",
    "   - **Action:** Collects duplicate rows and records an error comment: \"Duplicate account number on the same reference date\".\n",
    "\n",
    "3. **Negative Amount Check**\n",
    "   - **Description:** Checks if the 'amount' column has any negative values.\n",
    "   - **Action:** Collects rows with negative amounts and records an error comment: \"Negative amount\".\n",
    "\n",
    "4. **Valid Reference Date Check**\n",
    "   - **Description:** Checks if the 'reference_date' column contains valid dates.\n",
    "   - **Action:** Collects rows with invalid dates and records an error comment: \"Invalid date in 'reference_date'\".\n",
    "\n",
    "5. **Valid Account Number Check**\n",
    "   - **Description:** Checks if the 'account_number' column contains valid integers.\n",
    "   - **Action:** Collects rows where 'account_number' contains non-integer values and records an error comment: \"'account_number' contains non-integer values\".\n",
    "\n",
    "6. **Valid Amount Check**\n",
    "   - **Description:** Checks if the 'amount' column contains valid floats.\n",
    "   - **Action:** Collects rows where 'amount' contains non-float values and records an error comment: \"'amount' contains non-float values\".\n",
    "\n",
    "7. **Valid Account Type Check**\n",
    "   - **Description:** Checks if the 'account_type' column only contains 'Asset' or 'Liability'.\n",
    "   - **Action:** Collects rows where 'account_type' contains invalid values and records an error comment: \"'account_type' contains invalid values\".\n",
    "\n",
    "8. **Valid Account Name Check**\n",
    "   - **Description:** Checks if the 'account_name' column follows the expected pattern: `^(Unsecured Personal Loan|Credit Card|Corporate Leasing|Fixed|Floating) - (EUR|NOK|SEK)$`.\n",
    "   - **Action:** Collects rows where 'account_name' contains invalid values and records an error comment: \"'account_name' contains invalid values\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epranei\\AppData\\Local\\Temp\\ipykernel_8992\\3204868860.py:43: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if not df['account_name'].str.contains(r'^(Unsecured Personal Loan|Credit Card|Corporate Leasing|Fixed|Floating) - (EUR|NOK|SEK)$').all():\n",
      "C:\\Users\\epranei\\AppData\\Local\\Temp\\ipykernel_8992\\3204868860.py:44: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  for index, row in df[~df['account_name'].str.contains(r'^(Unsecured Personal Loan|Credit Card|Corporate Leasing|Fixed|Floating) - (EUR|NOK|SEK)$')].iterrows():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def validate_data(df):\n",
    "    error_list = []\n",
    "\n",
    "    # check for missing values\n",
    "    if df.isnull().values.any():\n",
    "        for index, row in df[df.isnull().any(axis=1)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Missing values in the row\"])\n",
    "\n",
    "    # Check for duplicate account numbers on the same reference date\n",
    "    duplicate_mask = df.duplicated(subset=['account_number', 'reference_date'], keep=False)\n",
    "    if duplicate_mask.any():\n",
    "        for index, row in df[duplicate_mask].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Duplicate account number on the same reference date\"])\n",
    "\n",
    "    # Check if 'amount' column has negative values\n",
    "    if (df['amount'] < 0).any():\n",
    "        for index, row in df[df['amount'] < 0].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Negative amount\"])\n",
    "\n",
    "    # Check if 'reference_date' column has valid dates\n",
    "    try:\n",
    "        pd.to_datetime(df['reference_date'], format='%m/%d/%y')\n",
    "    except ValueError:\n",
    "        for index, row in df[~pd.to_datetime(df['reference_date'], errors='coerce').notna()].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Invalid date in 'reference_date'\"])\n",
    "\n",
    "    # Check if 'account_number' column has valid integers\n",
    "    if not pd.api.types.is_integer_dtype(df['account_number']):\n",
    "        for index, row in df[~df['account_number'].apply(lambda x: isinstance(x, int))].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"'account_number' contains non-integer values\"])\n",
    "\n",
    "    # Check if 'amount' column has valid floats\n",
    "    if not pd.api.types.is_float_dtype(df['amount']):\n",
    "        for index, row in df[~df['amount'].apply(lambda x: isinstance(x, float))].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"'amount' contains non-float values\"])\n",
    "\n",
    "    # Check if 'account_type' only contains 'Asset' or 'Liability'\n",
    "    if not df['account_type'].isin(['Asset', 'Liability']).all():\n",
    "        for index, row in df[~df['account_type'].isin(['Asset', 'Liability'])].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"'account_type' contains invalid values\"])\n",
    "\n",
    "    # Check if 'account_name' follows the expected pattern\n",
    "    if not df['account_name'].str.contains(r'^(Unsecured Personal Loan|Credit Card|Corporate Leasing|Fixed|Floating) - (EUR|NOK|SEK)$').all():\n",
    "        for index, row in df[~df['account_name'].str.contains(r'^(Unsecured Personal Loan|Credit Card|Corporate Leasing|Fixed|Floating) - (EUR|NOK|SEK)$')].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"'account_name' contains invalid values\"])\n",
    "\n",
    "    # Create a dataframe to hold errors\n",
    "    error_df = pd.DataFrame(error_list, columns=['row_index', 'row_data', 'comment'])\n",
    "\n",
    "    return error_df\n",
    "\n",
    "# Validate the dataframe\n",
    "validation_errors_df = validate_data(accounts_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = 'Processed_file/Invalid_data'\n",
    "output_file_name = 'invalid_accounts.xlsx'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save the validation errors dataframe to an Excel file\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "validation_errors_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned accounts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_accounts_df = accounts_df[~accounts_df.index.isin(validation_errors_df['row_index'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = cleaned_accounts_df[cleaned_accounts_df.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(duplicate_rows) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = 'Processed_file/Cleaned_data'\n",
    "output_file_name = 'cleaned_accounts.xlsx'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save the validation errors dataframe to an Excel file\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "cleaned_accounts_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   customer        500 non-null    object        \n",
      " 1   customer_type   500 non-null    object        \n",
      " 2   deposit_type    500 non-null    object        \n",
      " 3   country         500 non-null    object        \n",
      " 4   amount          500 non-null    float64       \n",
      " 5   currency        500 non-null    object        \n",
      " 6   exchange_rate   500 non-null    float64       \n",
      " 7   start_date      500 non-null    datetime64[ns]\n",
      " 8   maturity_date   142 non-null    datetime64[ns]\n",
      " 9   reference_date  500 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(2), object(5)\n",
      "memory usage: 39.2+ KB\n",
      "None\n",
      "                                            customer customer_type  \\\n",
      "0  0002767be2fd774f796f9a90dea9be48f6cbb41b6404ef...     Household   \n",
      "1  0010c866e31af49ac1e5286bc0606e6a34fc68daf68f52...     Household   \n",
      "2  00221a07b4ab91714997432490aeef35be55c15e47429c...     Household   \n",
      "3  0029d9489632a584e3e6492e109987159083b2843b391b...     Household   \n",
      "4  002db3caa61bfeeb6a8323aca83f02175f753bec5c9910...     Household   \n",
      "\n",
      "  deposit_type country   amount currency  exchange_rate start_date  \\\n",
      "0        Fixed      FI   1000.0      EUR         11.096 2023-10-31   \n",
      "1        Fixed      FI  70000.0      EUR         11.096 2023-01-23   \n",
      "2        Fixed      FI  10000.0      EUR         11.096 2023-08-29   \n",
      "3        Fixed      FI  10000.0      EUR         11.096 2023-12-19   \n",
      "4        Fixed      FI      0.0      EUR         11.096 2022-12-07   \n",
      "\n",
      "  maturity_date reference_date  \n",
      "0    2024-10-31     2023-12-31  \n",
      "1    2024-01-23     2023-12-31  \n",
      "2    2024-08-29     2023-12-31  \n",
      "3    2024-12-19     2023-12-31  \n",
      "4    2023-12-07     2023-12-31  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the schema for deposits_df\n",
    "dtype_schema = {\n",
    "    'customer': 'object',\n",
    "    'customer_type': 'object',\n",
    "    'deposit_type': 'object',\n",
    "    'country': 'object',\n",
    "    'amount': 'float64',\n",
    "    'currency': 'object',\n",
    "    'exchange_rate': 'float64',\n",
    "    'start_date': 'object',  # Initially read as string to handle parsing later\n",
    "    'maturity_date': 'object',  # Initially read as string to handle parsing later\n",
    "    'reference_date': 'object'  # Initially read as string to handle parsing later\n",
    "}\n",
    "\n",
    "# Columns that should be parsed as dates\n",
    "date_columns = ['start_date', 'maturity_date', 'reference_date']\n",
    "\n",
    "# Custom date parser for the specific date format in the Excel file\n",
    "date_parser = lambda x: pd.to_datetime(x, format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Read the Excel file with the specified schema and date format\n",
    "file_path = \"Datasets/Data Engineer Case Study - Data.xlsx\"\n",
    "deposits_df = pd.read_excel(file_path, sheet_name='Deposits', dtype=dtype_schema, parse_dates=date_columns)\n",
    "\n",
    "# Apply custom date parsing for date columns\n",
    "for date_col in date_columns:\n",
    "    deposits_df[date_col] = deposits_df[date_col].apply(date_parser)\n",
    "\n",
    "# Display the schema and a few rows to verify\n",
    "print(deposits_df.info())\n",
    "print(deposits_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deposits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposits_df['ingest_date_time'] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_output_path = 'Processed_file/Original_data'\n",
    "os.makedirs(original_output_path, exist_ok=True)\n",
    "original_output_file_path = os.path.join(original_output_path, 'original_deposits_with_ingest_date_time.xlsx')\n",
    "deposits_df.to_excel(original_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deposits Data Validation\n",
    "\n",
    "The following data validation checks have been performed on the `deposits_df` dataframe:\n",
    "\n",
    "1. **Missing Values Check**\n",
    "   - **Description:** Checks if there are any missing values in the dataframe.\n",
    "   - **Action:** Collects rows with missing values and records an error comment: \"Missing values in the row\".\n",
    "\n",
    "2. **Duplicate Customer Check**\n",
    "   - **Description:** Checks for duplicate customers based on the 'customer' column.\n",
    "   - **Action:** Collects duplicate rows and records an error comment: \"Duplicate customer\".\n",
    "\n",
    "3. **Negative or Zero Amount Check**\n",
    "   - **Description:** Checks if the 'amount' column has any negative or zero values.\n",
    "   - **Action:** Collects rows with negative or zero amounts and records an error comment: \"Amount is negative or zero\".\n",
    "\n",
    "4. **Valid Date Check**\n",
    "   - **Description:** Checks if the 'start_date', 'maturity_date', and 'reference_date' columns contain valid dates.\n",
    "   - **Action:** Collects rows with invalid dates in any of these columns and records an error comment: \"Invalid date in 'column_name'\".\n",
    "\n",
    "5. **Valid Currency Check**\n",
    "   - **Description:** Checks if the 'currency' column contains valid currency codes (e.g., EUR, USD, GBP, etc.).\n",
    "   - **Action:** Collects rows with invalid currency codes and records an error comment: \"Invalid currency\".\n",
    "\n",
    "6. **Valid Exchange Rate Check**\n",
    "   - **Description:** Checks if the 'exchange_rate' column contains valid floats and values greater than 0.\n",
    "   - **Action:** Collects rows with invalid or non-positive exchange rates and records an error comment: \"Invalid exchange rate\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>country</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchange_rate</th>\n",
       "      <th>start_date</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>reference_date</th>\n",
       "      <th>ingest_date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002767be2fd774f796f9a90dea9be48f6cbb41b6404ef...</td>\n",
       "      <td>Household</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>FI</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.096</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-05-21 20:02:36.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010c866e31af49ac1e5286bc0606e6a34fc68daf68f52...</td>\n",
       "      <td>Household</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>FI</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.096</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-05-21 20:02:36.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00221a07b4ab91714997432490aeef35be55c15e47429c...</td>\n",
       "      <td>Household</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>FI</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.096</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-05-21 20:02:36.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0029d9489632a584e3e6492e109987159083b2843b391b...</td>\n",
       "      <td>Household</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>FI</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.096</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-05-21 20:02:36.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002db3caa61bfeeb6a8323aca83f02175f753bec5c9910...</td>\n",
       "      <td>Household</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>FI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>11.096</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-05-21 20:02:36.074608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            customer customer_type  \\\n",
       "0  0002767be2fd774f796f9a90dea9be48f6cbb41b6404ef...     Household   \n",
       "1  0010c866e31af49ac1e5286bc0606e6a34fc68daf68f52...     Household   \n",
       "2  00221a07b4ab91714997432490aeef35be55c15e47429c...     Household   \n",
       "3  0029d9489632a584e3e6492e109987159083b2843b391b...     Household   \n",
       "4  002db3caa61bfeeb6a8323aca83f02175f753bec5c9910...     Household   \n",
       "\n",
       "  deposit_type country   amount currency  exchange_rate start_date  \\\n",
       "0        Fixed      FI   1000.0      EUR         11.096 2023-10-31   \n",
       "1        Fixed      FI  70000.0      EUR         11.096 2023-01-23   \n",
       "2        Fixed      FI  10000.0      EUR         11.096 2023-08-29   \n",
       "3        Fixed      FI  10000.0      EUR         11.096 2023-12-19   \n",
       "4        Fixed      FI      0.0      EUR         11.096 2022-12-07   \n",
       "\n",
       "  maturity_date reference_date           ingest_date_time  \n",
       "0    2024-10-31     2023-12-31 2024-05-21 20:02:36.074608  \n",
       "1    2024-01-23     2023-12-31 2024-05-21 20:02:36.074608  \n",
       "2    2024-08-29     2023-12-31 2024-05-21 20:02:36.074608  \n",
       "3    2024-12-19     2023-12-31 2024-05-21 20:02:36.074608  \n",
       "4    2023-12-07     2023-12-31 2024-05-21 20:02:36.074608  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deposits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    error_list = []\n",
    "\n",
    "    # Check for missing values\n",
    "    if df.isnull().values.any():\n",
    "        for index, row in df[df.isnull().any(axis=1)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Missing values in the row\"])\n",
    "\n",
    "    # Check for duplicate customers\n",
    "    if df.duplicated(subset=['customer']).any():\n",
    "        for index, row in df[df.duplicated(subset=['customer'], keep=False)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Duplicate customer\"])\n",
    "\n",
    "    # Check if 'amount' column has negative or zero values\n",
    "    if (df['amount'] <= 0).any():\n",
    "        for index, row in df[df['amount'] <= 0].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Amount is negative or zero\"])\n",
    "\n",
    "    # Check if date columns have valid dates\n",
    "    for date_column in ['start_date', 'maturity_date', 'reference_date']:\n",
    "        try:\n",
    "            pd.to_datetime(df[date_column])\n",
    "        except ValueError:\n",
    "            for index, row in df[~pd.to_datetime(df[date_column], errors='coerce').notna()].iterrows():\n",
    "                error_list.append([index, row.to_dict(), f\"Invalid date in '{date_column}'\"])\n",
    "\n",
    "    # Check if 'currency' column has valid currencies (assuming valid currencies are EUR, USD, GBP, etc.)\n",
    "    valid_currencies = ['EUR', 'USD', 'GBP', 'NOK', 'SEK']\n",
    "    if not df['currency'].isin(valid_currencies).all():\n",
    "        for index, row in df[~df['currency'].isin(valid_currencies)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Invalid currency\"])\n",
    "\n",
    "    # Check if 'exchange_rate' column has valid floats and is greater than 0\n",
    "    if not pd.api.types.is_float_dtype(df['exchange_rate']) or (df['exchange_rate'] <= 0).any():\n",
    "        for index, row in df[~df['exchange_rate'].apply(lambda x: isinstance(x, float) and x > 0)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Invalid exchange rate\"])\n",
    "\n",
    "    # Create a dataframe to hold errors\n",
    "    error_df = pd.DataFrame(error_list, columns=['row_index', 'row_data', 'comment'])\n",
    "\n",
    "    return error_df\n",
    "\n",
    "validation_errors_df = validate_data(deposits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Processed_file/Invalid_data'\n",
    "output_file_name = 'invalid_deposits.xlsx'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save the validation errors dataframe to an Excel file\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "validation_errors_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned_Deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_deposits_df = deposits_df[~deposits_df.index.isin(validation_errors_df['row_index'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cleaned_deposits_df[cleaned_deposits_df.duplicated()]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output_path = 'Processed_file/Cleaned_data'\n",
    "os.makedirs(cleaned_output_path, exist_ok=True)\n",
    "cleaned_output_file_path = os.path.join(cleaned_output_path, 'cleaned_deposits.xlsx')\n",
    "cleaned_deposits_df.to_excel(cleaned_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   customer        500 non-null    object        \n",
      " 1   customer_type   500 non-null    object        \n",
      " 2   loan_type       500 non-null    object        \n",
      " 3   country         500 non-null    object        \n",
      " 4   amount          500 non-null    float64       \n",
      " 5   currency        500 non-null    object        \n",
      " 6   exchange_rate   500 non-null    float64       \n",
      " 7   start_date      499 non-null    datetime64[ns]\n",
      " 8   maturity_date   500 non-null    datetime64[ns]\n",
      " 9   reference_date  500 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(2), object(5)\n",
      "memory usage: 39.2+ KB\n",
      "None\n",
      "                                            customer customer_type  \\\n",
      "0  01f259b4c6ce07c68d37c859cf6dfe063fb75fedf39464...     Household   \n",
      "1  01f9cbc3a44cfb87f57a2faee345dd4451075e6de7439e...     Household   \n",
      "2  0032d8a52578e8b96416398d6ee409cc33c6209a3b7829...     Household   \n",
      "3  00df76c5c449083831102e0a85377b3b07ee70c8968d20...     Household   \n",
      "4  02483eae1c55a920ad32ca82503f5fa8775d257ccb9502...     Household   \n",
      "\n",
      "                 loan_type country    amount currency  exchange_rate  \\\n",
      "0  Unsecured Personal Loan      FI   4540.00      EUR       11.43080   \n",
      "1  Unsecured Personal Loan      FI     96.59      EUR       11.43080   \n",
      "2              Credit Card      NO  14735.12      NOK        0.97532   \n",
      "3              Credit Card      NO   8391.74      NOK        0.97532   \n",
      "4              Credit Card      NO  14267.64      NOK        0.97532   \n",
      "\n",
      "  start_date maturity_date reference_date  \n",
      "0 2027-09-09    2021-09-09     2023-11-30  \n",
      "1 2026-09-01    2021-09-01     2023-11-30  \n",
      "2 2024-08-18    2023-08-18     2023-11-30  \n",
      "3 2024-08-29    2023-08-29     2023-11-30  \n",
      "4 2024-09-01    2023-09-01     2023-11-30  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the schema for loans_df\n",
    "dtype_schema = {\n",
    "    'customer': 'object',\n",
    "    'customer_type': 'object',\n",
    "    'loan_type': 'object',\n",
    "    'country': 'object',\n",
    "    'amount': 'float64',\n",
    "    'currency': 'object',\n",
    "    'exchange_rate': 'float64',\n",
    "    'start_date': 'object',  # Initially read as string to handle parsing later\n",
    "    'maturity_date': 'object',  # Initially read as string to handle parsing later\n",
    "    'reference_date': 'object'  # Initially read as string to handle parsing later\n",
    "}\n",
    "\n",
    "# Columns that should be parsed as dates\n",
    "date_columns = ['start_date', 'maturity_date', 'reference_date']\n",
    "\n",
    "# Custom date parser for the specific date format in the Excel file\n",
    "date_parser = lambda x: pd.to_datetime(x, format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Read the Excel file with the specified schema and date format\n",
    "file_path = \"Datasets/Data Engineer Case Study - Data.xlsx\"\n",
    "loans_df = pd.read_excel(file_path, sheet_name='Loans', dtype=dtype_schema, parse_dates=date_columns)\n",
    "\n",
    "# Apply custom date parsing for date columns\n",
    "for date_col in date_columns:\n",
    "    loans_df[date_col] = loans_df[date_col].apply(date_parser)\n",
    "\n",
    "# Display the schema and a few rows to verify\n",
    "print(loans_df.info())\n",
    "print(loans_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df['ingest_date_time'] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_output_path = 'Processed_file/Original_data'\n",
    "os.makedirs(original_output_path, exist_ok=True)\n",
    "original_output_file_path = os.path.join(original_output_path, 'original_loans_with_ingest_date_time.xlsx')\n",
    "loans_df.to_excel(original_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loans Data Validation\n",
    "\n",
    "The following data validation checks have been performed on the `loans_df` dataframe:\n",
    "\n",
    "1. **Missing Values Check**\n",
    "   - **Description:** Checks if there are any missing values in the dataframe.\n",
    "   - **Action:** Collects rows with missing values and records an error comment: \"Missing values in the row\".\n",
    "\n",
    "2. **Duplicate Customer Check**\n",
    "   - **Description:** Checks for duplicate customers based on the 'customer' column.\n",
    "   - **Action:** Collects duplicate rows and records an error comment: \"Duplicate customer\".\n",
    "\n",
    "3. **Negative or Zero Amount Check**\n",
    "   - **Description:** Checks if the 'amount' column has any negative or zero values.\n",
    "   - **Action:** Collects rows with negative or zero amounts and records an error comment: \"Amount is negative or zero\".\n",
    "\n",
    "4. **Valid Date Check**\n",
    "   - **Description:** Checks if the 'start_date', 'maturity_date', and 'reference_date' columns contain valid dates.\n",
    "   - **Action:** Collects rows with invalid dates in any of these columns and records an error comment: \"Invalid date in 'column_name'\".\n",
    "\n",
    "5. **Valid Currency Check**\n",
    "   - **Description:** Checks if the 'currency' column contains valid currency codes (e.g., EUR, USD, GBP, NOK, SEK).\n",
    "   - **Action:** Collects rows with invalid currency codes and records an error comment: \"Invalid currency\".\n",
    "\n",
    "6. **Valid Exchange Rate Check**\n",
    "   - **Description:** Checks if the 'exchange_rate' column contains valid floats and values greater than 0.\n",
    "   - **Action:** Collects rows with invalid or non-positive exchange rates and records an error comment: \"Invalid exchange rate\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    error_list = []\n",
    "\n",
    "    # Check for missing values\n",
    "    if df.isnull().values.any():\n",
    "        for index, row in df[df.isnull().any(axis=1)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Missing values in the row\"])\n",
    "\n",
    "    # Check for duplicate customers\n",
    "    if df.duplicated(subset=['customer']).any():\n",
    "        for index, row in df[df.duplicated(subset=['customer'], keep=False)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Duplicate customer\"])\n",
    "\n",
    "    # Check if 'amount' column has negative or zero values\n",
    "    if (df['amount'] <= 0).any():\n",
    "        for index, row in df[df['amount'] <= 0].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Amount is negative or zero\"])\n",
    "\n",
    "    # Check if date columns have valid dates\n",
    "    for date_column in ['start_date', 'maturity_date', 'reference_date']:\n",
    "        try:\n",
    "            pd.to_datetime(df[date_column])\n",
    "        except ValueError:\n",
    "            for index, row in df[~pd.to_datetime(df[date_column], errors='coerce').notna()].iterrows():\n",
    "                error_list.append([index, row.to_dict(), f\"Invalid date in '{date_column}'\"])\n",
    "\n",
    "    # Check if 'currency' column has valid currencies (assuming valid currencies are EUR, USD, GBP, etc.)\n",
    "    valid_currencies = ['EUR', 'USD', 'GBP', 'NOK', 'SEK']\n",
    "    if not df['currency'].isin(valid_currencies).all():\n",
    "        for index, row in df[~df['currency'].isin(valid_currencies)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Invalid currency\"])\n",
    "\n",
    "    # Check if 'exchange_rate' column has valid floats and is greater than 0\n",
    "    if not pd.api.types.is_float_dtype(df['exchange_rate']) or (df['exchange_rate'] <= 0).any():\n",
    "        for index, row in df[~df['exchange_rate'].apply(lambda x: isinstance(x, float) and x > 0)].iterrows():\n",
    "            error_list.append([index, row.to_dict(), \"Invalid exchange rate\"])\n",
    "\n",
    "    # Create a dataframe to hold errors\n",
    "    error_df = pd.DataFrame(error_list, columns=['row_index', 'row_data', 'comment'])\n",
    "\n",
    "    return error_df\n",
    "\n",
    "# Validate the dataframe\n",
    "validation_errors_df = validate_data(loans_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'Processed_file/Invalid_data'\n",
    "output_file_name = 'invalid_loans.xlsx'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save the validation errors dataframe to an Excel file\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "validation_errors_df.to_excel(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_loans_df = loans_df[~loans_df.index.isin(validation_errors_df['row_index'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(cleaned_loans_df[cleaned_loans_df.duplicated()]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output_path = 'Processed_file/Cleaned_data'\n",
    "os.makedirs(cleaned_output_path, exist_ok=True)\n",
    "cleaned_output_file_path = os.path.join(cleaned_output_path, 'cleaned_loans.xlsx')\n",
    "cleaned_loans_df.to_excel(cleaned_output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 300 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   customer          300 non-null    object        \n",
      " 1   customer_type     300 non-null    object        \n",
      " 2   loan_type         300 non-null    object        \n",
      " 3   country           300 non-null    object        \n",
      " 4   amount            300 non-null    float64       \n",
      " 5   currency          300 non-null    object        \n",
      " 6   exchange_rate     300 non-null    float64       \n",
      " 7   start_date        300 non-null    datetime64[ns]\n",
      " 8   maturity_date     300 non-null    datetime64[ns]\n",
      " 9   reference_date    300 non-null    datetime64[ns]\n",
      " 10  ingest_date_time  300 non-null    datetime64[us]\n",
      "dtypes: datetime64[ns](3), datetime64[us](1), float64(2), object(5)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaned_loans_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advicense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
